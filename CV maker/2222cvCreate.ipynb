{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install python-docx\n",
    "#!pip3 install openai\n",
    "#!pip3 install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os       # For file path operations\n",
    "import re       # For regular expressions (finding keywords)\n",
    "import requests # For making HTTP requests to fetch job description\n",
    "from docx import Document     # From python-docx for reading/writing Word documents\n",
    "from docx.shared import Pt    # For setting font sizes, etc.\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "from datetime import datetime, timedelta\n",
    "import undetected_chromedriver as uc\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the job from linked in then put the file as input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Scraping LinkedIn Jobs...\n",
      "\n",
      "\n",
      "âœ… Jobs saved to /home/shyam/Downloads/Job-apply-AI-agent-main (2)/CV maker/linkedin_jobs_2025-10-14.xlsx\n"
     ]
    }
   ],
   "source": [
    "def configure_driver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    driver = uc.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "def scrape_linkedin_jobs(keyword, location):\n",
    "    print(\"\\nðŸ” Scraping LinkedIn Jobs...\\n\")\n",
    "    driver = configure_driver()\n",
    "    search_url = f\"https://www.linkedin.com/jobs/search?keywords={keyword.replace(' ', '%20')}&location={location.replace(' ', '%20')}\"\n",
    "    driver.get(search_url)\n",
    "    \n",
    "    for _ in range(3):  \n",
    "        driver.execute_script(\"window.scrollBy(0, 800);\")\n",
    "        time.sleep(2)\n",
    "    \n",
    "    wait = WebDriverWait(driver, 15)\n",
    "    try:\n",
    "        wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"base-card\")))\n",
    "    except:\n",
    "        print(\"âŒ No LinkedIn jobs found.\")\n",
    "        driver.quit()\n",
    "        return []\n",
    "\n",
    "    jobs = []\n",
    "    today = datetime.today()\n",
    "    job_elements = driver.find_elements(By.CLASS_NAME, \"base-card\")\n",
    "    \n",
    "    for job in job_elements[:10]:\n",
    "        try:\n",
    "            title = job.find_element(By.CSS_SELECTOR, \"h3\").text.strip()\n",
    "            company = job.find_element(By.CSS_SELECTOR, \"h4\").text.strip()\n",
    "            link = job.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "            \n",
    "            try:\n",
    "                date_element = job.find_element(By.CSS_SELECTOR, \"time\")\n",
    "                posted_time = date_element.get_attribute(\"datetime\")\n",
    "                if posted_time:\n",
    "                    posted_date = datetime.strptime(posted_time[:10], \"%Y-%m-%d\")\n",
    "                    days_ago = (today - posted_date).days\n",
    "                    if days_ago > 14:\n",
    "                        print(f\"â³ Skipping job: {title} (Posted {days_ago} days ago)\")\n",
    "                        continue\n",
    "            except:\n",
    "                print(f\"âš ï¸ Could not find post time for: {title}, assuming it's recent.\")\n",
    "                days_ago = \"Unknown\"\n",
    "            \n",
    "            jobs.append({\"title\": title, \"company\": company, \"link\": link, \"source\": \"LinkedIn\", \"posted_days_ago\": days_ago})\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Skipping a job entry due to error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    driver.quit()\n",
    "    return jobs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    keyword = input(\"Enter job title (e.g., Software Engineer): \")\n",
    "    location = input(\"Enter location (e.g., Remote, New York, Berlin): \")\n",
    "    \n",
    "    linkedin_jobs = scrape_linkedin_jobs(keyword, location)\n",
    "    \n",
    "    if linkedin_jobs:\n",
    "        df = pd.DataFrame(linkedin_jobs)\n",
    "        today_date = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "        filename = f\"linkedin_jobs_{today_date}.xlsx\"\n",
    "        \n",
    "        folder_path = \"/home/shyam/Downloads/Job-apply-AI-agent-main (2)/CV maker\"\n",
    "        os.makedirs(folder_path, exist_ok=True)  # Ensure directory exists\n",
    "        input_file = os.path.join(folder_path, filename)\n",
    "        \n",
    "        df.to_excel(input_file, index=False)\n",
    "        print(f\"\\nâœ… Jobs saved to {input_file}\")\n",
    "    else:\n",
    "        print(\"\\nâŒ No LinkedIn jobs found.\")\n",
    "        input_file = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shyam/Downloads/Job-apply-AI-agent-main (2)/CV maker/linkedin_jobs_2025-10-14.xlsx\n"
     ]
    }
   ],
   "source": [
    "#chekcing the input file is getting correctly\n",
    "print(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the description of the job. fetch_full_job_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_full_job_details(job_url: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Opens the LinkedIn job page, fetches the job title, company name, and full job description.\n",
    "    Returns (job_title, company_name, job_description).\n",
    "    \"\"\"\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")           # or remove this if you want to see the browser\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "    driver = uc.Chrome(options=options)\n",
    "    driver.get(job_url)\n",
    "\n",
    "    # Default empty values\n",
    "    job_title = \"\"\n",
    "    company_name = \"\"\n",
    "    job_description = \"\"\n",
    "\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "\n",
    "        # 1) Job Title (example selector)\n",
    "        title_elem = wait.until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"h1.topcard__title\"))\n",
    "        )\n",
    "        job_title = title_elem.get_attribute(\"innerText\")\n",
    "\n",
    "        # 2) Company Name (example selector)\n",
    "        company_elem = wait.until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"a.topcard__org-name-link\"))\n",
    "        )\n",
    "        company_name = company_elem.get_attribute(\"innerText\")\n",
    "\n",
    "        # 3) Full Job Description (often \"description__text\" class)\n",
    "        desc_elem = wait.until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"description__text\"))\n",
    "        )\n",
    "        job_description = desc_elem.get_attribute(\"innerText\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {job_url}: {e}\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return job_title.strip(), company_name.strip(), job_description.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After modifying the excel sheet with description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'final_job_descriptions.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load the updated Excel file\u001b[39;00m\n\u001b[32m      5\u001b[39m input_file = \u001b[33m\"\u001b[39m\u001b[33mfinal_job_descriptions.xlsx\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Define your existing skills and categories\u001b[39;00m\n\u001b[32m      9\u001b[39m my_skills = {\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mData Science & Machine Learning\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33mPython\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mR\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mTensorFlow\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mNumPy\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mPandas\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSeaborn\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mScikit-learn\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mStatistical Modeling & AI\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33mML models\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAI\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mCustom-GPT\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDeep Learning\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mMicrosoft Tools\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33mAzure\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mMicrosoft 365\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDynamics 365\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     17\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Job-apply-AI-agent-main (2)/venv/lib/python3.12/site-packages/pandas/io/excel/_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Job-apply-AI-agent-main (2)/venv/lib/python3.12/site-packages/pandas/io/excel/_base.py:1550\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1548\u001b[39m     ext = \u001b[33m\"\u001b[39m\u001b[33mxls\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1550\u001b[39m     ext = \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1553\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1554\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1555\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mExcel file format cannot be determined, you must specify \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1556\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33man engine manually.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1557\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Job-apply-AI-agent-main (2)/venv/lib/python3.12/site-packages/pandas/io/excel/_base.py:1402\u001b[39m, in \u001b[36minspect_excel_format\u001b[39m\u001b[34m(content_or_path, storage_options)\u001b[39m\n\u001b[32m   1399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m   1400\u001b[39m     content_or_path = BytesIO(content_or_path)\n\u001b[32m-> \u001b[39m\u001b[32m1402\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   1404\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[32m   1405\u001b[39m     stream = handle.handle\n\u001b[32m   1406\u001b[39m     stream.seek(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Job-apply-AI-agent-main (2)/venv/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'final_job_descriptions.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the updated Excel file\n",
    "input_file = \"final_job_descriptions.xlsx\"\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# Define your existing skills and categories\n",
    "my_skills = {\n",
    "    \"Data Science & Machine Learning\": [\"Python\", \"R\", \"TensorFlow\", \"NumPy\", \"Pandas\", \"Seaborn\", \"Scikit-learn\"],\n",
    "    \"Statistical Modeling & AI\": [\"ML models\", \"AI\", \"Custom-GPT\", \"Deep Learning\"],\n",
    "    \"AI Agent\": [\"n8n\", \"Python AI Agent\", \"Automation\"],\n",
    "    \"Business Intelligence & Dashboarding\": [\"Power BI\", \"Tableau\", \"SQL\", \"Data Visualization\"],\n",
    "    \"Database Optimization\": [\"SQL\", \"MySQL\", \"PostgreSQL\"],\n",
    "    \"Programming Languages\": [\"Python\", \"Java\", \"C\", \"JavaScript\"],\n",
    "    \"Microsoft Tools\": [\"Azure\", \"Microsoft 365\", \"Dynamics 365\"]\n",
    "}\n",
    "\n",
    "# Common requirement phrases\n",
    "requirement_keywords = [\"experience in\", \"knowledge of\", \"proficiency in\", \"familiarity with\", \"required\", \"preferred\", \"must have\", \"ability to\"]\n",
    "\n",
    "def extract_skills_and_requirements(description):\n",
    "    \"\"\"\n",
    "    Extracts relevant skills and job requirements from the job description\n",
    "    based on predefined skills and requirement keywords.\n",
    "    \"\"\"\n",
    "    description = description.lower()  # Convert to lowercase for easier matching\n",
    "\n",
    "    # Identify matching skills\n",
    "    matched_skills = set()\n",
    "    for category, skills in my_skills.items():\n",
    "        for skill in skills:\n",
    "            pattern = rf\"\\b{re.escape(skill.lower())}\\b\"\n",
    "            if re.search(pattern, description):\n",
    "                matched_skills.add(skill)\n",
    "\n",
    "    # Extract job requirements based on common keywords\n",
    "    matched_requirements = set()\n",
    "    for keyword in requirement_keywords:\n",
    "        if keyword in description:\n",
    "            matched_requirements.add(keyword)\n",
    "\n",
    "    return list(matched_skills), list(matched_requirements)\n",
    "\n",
    "def process_job_descriptions(df, desc_col=\"description\", title_col=\"title\"):\n",
    "    \"\"\"\n",
    "    Extracts skills and requirements from job descriptions and stores them in the DataFrame.\n",
    "    \"\"\"\n",
    "    skills_list = []\n",
    "    requirements_list = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        description_text = str(row.get(desc_col, \"\"))\n",
    "        job_title = str(row.get(title_col, \"No Title Provided\"))\n",
    "\n",
    "        if not description_text.strip():\n",
    "            skills_list.append([])\n",
    "            requirements_list.append([])\n",
    "            continue\n",
    "        \n",
    "        matched_skills, matched_requirements = extract_skills_and_requirements(description_text)\n",
    "        skills_list.append(matched_skills)\n",
    "        requirements_list.append(matched_requirements)\n",
    "\n",
    "    df[\"Extracted Skills\"] = skills_list\n",
    "    df[\"Extracted Requirements\"] = requirements_list\n",
    "    return df\n",
    "\n",
    "# Process the job descriptions and display results\n",
    "df = process_job_descriptions(df)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting some keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
